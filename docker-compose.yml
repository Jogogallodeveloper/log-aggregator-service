services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.13.4
    container_name: logagg-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
    volumes:
      - esdata:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:9200 >/dev/null || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 60
      start_period: 30s

  kibana:
    image: docker.elastic.co/kibana/kibana:8.13.4
    container_name: logagg-kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
      elasticsearch:
        condition: service_healthy
    ports:
      - "5601:5601"
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://localhost:5601/api/status >/dev/null || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 60
      start_period: 30s

  kibana_setup:
    image: curlimages/curl:8.5.0
    container_name: logagg-kibana-setup
    depends_on:
      kibana:
        condition: service_healthy
    volumes:
      - ./kibana:/kibana
    entrypoint: ["/bin/sh", "-c"]
    command: >
      echo "Waiting for Kibana..." &&
      until curl -fsS http://kibana:5601/api/status > /dev/null; do sleep 5; done &&
      echo "Importing dashboard..." &&
      curl -fsS -X POST "http://kibana:5601/api/saved_objects/_import?overwrite=true"
      -H "kbn-xsrf: true"
      --form file=@/kibana/log-aggregator-overview.ndjson &&
      echo "Done."

  api:
    build: .
    container_name: logagg-api
    ports:
      - "3000:3000"
    environment:
      - ELASTICSEARCH_URL=http://elasticsearch:9200
    depends_on:
      elasticsearch:
        condition: service_healthy

volumes:
  esdata:
